#!/usr/bin/env python3
"""
æ ¹æ®12æœˆ7æ—¥çš„ä¿®å¤æ–¹æ¡ˆï¼Œæ‰¹é‡ä¿®å¤IndexTTSçš„ç¼©è¿›å’Œå…¼å®¹æ€§é—®é¢˜
"""
import re

files_to_fix = {
    'index-tts/indextts/infer_v2.py': [
        (79, 'self.qwen_emo'),  # tryå—å†…éœ€è¦ç¼©è¿›
        (388, 'if emo_text'),    # elseå—å†…éœ€è¦ç¼©è¿›
        (389, 'emo_text = text'),
        (390, 'emo_dict'),
    ],
    'index-tts/indextts/gpt/transformers_generation_utils.py': [
        (36, 'from transformers.integrations.fsdp'),  # tryå—å†…éœ€è¦ç¼©è¿›
    ]
}

def fix_indentation(filepath, line_rules):
    """ä¿®å¤æ–‡ä»¶ç¼©è¿›"""
    print(f"ä¿®å¤: {filepath}")
    
    with open(filepath, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    fixed_count = 0
    for line_num, pattern in line_rules:
        idx = line_num - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
        if idx < len(lines):
            line = lines[idx]
            if pattern in line and not line.startswith('    '):
                # æ·»åŠ 4ä¸ªç©ºæ ¼ç¼©è¿›
                lines[idx] = '    ' + line.lstrip()
                print(f"  âœ… ç¬¬{line_num}è¡Œå·²ä¿®å¤ç¼©è¿›")
                fixed_count += 1
    
    if fixed_count > 0:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.writelines(lines)
        print(f"  å…±ä¿®å¤ {fixed_count} å¤„ç¼©è¿›\n")
    else:
        print(f"  æ— éœ€ä¿®å¤\n")

def add_compatibility_imports():
    """æ·»åŠ å…¼å®¹æ€§importsåˆ°transformers_generation_utils.py"""
    filepath = 'index-tts/indextts/gpt/transformers_generation_utils.py'
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å¦‚æœå·²ç»æœ‰fallbackï¼Œè·³è¿‡
    if 'isin_mps_friendly' in content and 'def isin_mps_friendly' in content:
        print("transformers_generation_utils.py å·²æœ‰å…¼å®¹æ€§ä¿®å¤")
        return
    
    # åœ¨æ–‡ä»¶å¼€å¤´çš„importsåæ·»åŠ å…¼å®¹æ€§ä»£ç 
    compatibility_code = '''
# ========== Compatibility fixes for transformers 4.40.0 ==========
# These imports may not be available in all transformers versions
# Add fallback implementations to ensure compatibility

# Fix 1: EncoderDecoderCache
try:
    from transformers.cache_utils import EncoderDecoderCache
except ImportError:
    EncoderDecoderCache = None

# Fix 2: OffloadedCache  
try:
    from transformers.cache_utils import OffloadedCache
except ImportError:
    OffloadedCache = None

# Fix 3: QuantizedCacheConfig
try:
    from transformers.cache_utils import QuantizedCacheConfig
except ImportError:
    class QuantizedCacheConfig:
        pass

# Fix 4: isin_mps_friendly
try:
    from transformers.pytorch_utils import isin_mps_friendly
except ImportError:
    import torch
    def isin_mps_friendly(elements, test_elements):
        if isinstance(test_elements, int):
            return elements == test_elements
        return torch.isin(elements, test_elements)

# Fix 5: ExtensionsTrie
try:
    from transformers.tokenization_utils import ExtensionsTrie
except ImportError:
    class ExtensionsTrie:
        def __init__(self, vocab):
            pass
# ========== End of compatibility fixes ==========
'''
    
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªfrom transformers importä¹‹åæ’å…¥
    lines = content.split('\n')
    insert_pos = -1
    
    for i, line in enumerate(lines):
        if i > 20 and 'from transformers' in line and insert_pos == -1:
            # åœ¨æ‰€æœ‰transformers importsä¹‹åæ’å…¥
            if i < len(lines) - 1 and 'from transformers' not in lines[i+1]:
                insert_pos = i + 1
                break
    
    if insert_pos > 0:
        lines.insert(insert_pos, compatibility_code)
        new_content = '\n'.join(lines)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(new_content)
        print("âœ… transformers_generation_utils.py å·²æ·»åŠ å…¼å®¹æ€§ä¿®å¤\n")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°åˆé€‚çš„æ’å…¥ä½ç½®\n")

if __name__ == '__main__':
    print("ğŸ”§ åº”ç”¨IndexTTSä¿®å¤...")
    print("="*60)
    
    # ä¿®å¤ç¼©è¿›
    for filepath, rules in files_to_fix.items():
        fix_indentation(filepath, rules)
    
    # æ·»åŠ å…¼å®¹æ€§imports
    add_compatibility_imports()
    
    print("="*60)
    print("âœ… æ‰€æœ‰ä¿®å¤å·²åº”ç”¨ï¼")
    print("\nä¸‹ä¸€æ­¥ï¼šæ¸…ç†ç¼“å­˜å¹¶é‡å¯æœåŠ¡")
    print("  find . -name '__pycache__' -type d -delete")
    print("  pkill -f uvicorn && python -m uvicorn backend.app.main:app --host 0.0.0.0 --port 8000")




