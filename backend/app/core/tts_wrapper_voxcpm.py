"""
VoxCPM TTSå¼•æ“å°è£…
æ›¿ä»£IndexTTSï¼Œæä¾›æ›´å¥½çš„å…¼å®¹æ€§å’Œæ€§èƒ½
"""
import sys
import os
import asyncio
import logging
import uuid
from concurrent.futures import ThreadPoolExecutor
from backend.app.core.config import settings

logger = logging.getLogger(__name__)

class VoxCPMEngine:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(VoxCPMEngine, cls).__new__(cls)
            cls._instance.model = None
            # queue å»¶è¿Ÿåˆ°åˆå§‹åŒ–æ—¶ç»‘å®šå½“å‰äº‹ä»¶å¾ªç¯ï¼Œé¿å…è·¨äº‹ä»¶å¾ªç¯æŒ‚èµ·
            cls._instance.queue = None
            cls._instance.executor = ThreadPoolExecutor(max_workers=1)
        return cls._instance

    def initialize(self):
        """åˆå§‹åŒ–VoxCPMæ¨¡å‹"""
        if self.model is not None:
            print("VoxCPM Model already initialized.")
            logger.info("VoxCPM Model already initialized.")
            return

        print("Initializing VoxCPM Model...")
        logger.info("Initializing VoxCPM Model...")
        try:
            from voxcpm import VoxCPM
            
            print("Loading VoxCPM1.5 from HuggingFace...")
            # åŠ è½½VoxCPM1.5æ¨¡å‹
            # æ³¨æ„ï¼šoptimize=False é¿å…åœ¨ThreadPoolExecutorä¸­ä½¿ç”¨torch.compileæ—¶çš„çº¿ç¨‹å®‰å…¨é—®é¢˜
            self.model = VoxCPM.from_pretrained(
                hf_model_id="openbmb/VoxCPM1.5",
                load_denoiser=True,  # åŠ è½½é™å™ªå™¨
                optimize=False  # ç¦ç”¨ä¼˜åŒ–ä»¥é¿å…çº¿ç¨‹å®‰å…¨é—®é¢˜
            )
            
            print(f"âœ… VoxCPM Model initialized successfully!")
            print(f"   é‡‡æ ·ç‡: {self.model.tts_model.sample_rate}")
            print(f"   è®¾å¤‡: {self.model.tts_model.device}")
            print(f"   æ¨¡å‹å¯¹è±¡: {self.model}")
            
            logger.info(f"âœ… VoxCPM Model initialized successfully!")
            logger.info(f"   é‡‡æ ·ç‡: {self.model.tts_model.sample_rate}")
            logger.info(f"   è®¾å¤‡: {self.model.tts_model.device}")
            
            # ç»‘å®šqueueåˆ°å½“å‰äº‹ä»¶å¾ªç¯ï¼Œé˜²æ­¢æ—§loopå¯¼è‡´get/puté˜»å¡
            self.queue = asyncio.Queue()
            print("Queue created and bound to current event loop.")
            logger.info("Queue created and bound to current event loop.")
            
        except Exception as e:
            print(f"âŒ Failed to initialize VoxCPM Model: {e}")
            logger.error(f"Failed to initialize VoxCPM Model: {e}")
            import traceback
            traceback.print_exc()
            raise e

    async def process_queue(self):
        """åå°workerå¤„ç†TTSä»»åŠ¡é˜Ÿåˆ—"""
        print("="*60)
        print("ğŸš€ VoxCPM Worker started!")
        print("="*60)
        print(f"[Worker] queue id: {id(self.queue)}")
        logger.info("VoxCPM Worker started.")
        
        while True:
            print(f"â³ Waiting for task from queue... (model: {self.model is not None}) queue id: {id(self.queue)} size: {self.queue.qsize() if self.queue else 'None'}")
            task_data = await self.queue.get()
            task_id, text, voice_path, future = task_data
            
            print(f"ğŸ“ Got task {task_id}: {text[:50]}")
            
            try:
                print(f"ğŸµ Processing task {task_id}...")
                logger.info(f"Processing task {task_id}...")
                
                output_filename = f"{task_id}.wav"
                output_path = os.path.join(settings.GENERATED_AUDIO_DIR, output_filename)
                
                print(f"   è¾“å‡ºè·¯å¾„: {output_path}")
                print(f"   éŸ³è‰²æ–‡ä»¶: {voice_path}")
                
                # åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œæ¨ç†
                loop = asyncio.get_event_loop()
                print(f"   å¼€å§‹æ¨ç†...")
                await loop.run_in_executor(
                    self.executor,
                    self._run_inference,
                    text,
                    voice_path,
                    output_path
                )
                
                print(f"   æ¨ç†å®Œæˆï¼Œè®¾ç½®ç»“æœ...")
                # è®¾ç½®ç»“æœ
                future.set_result(f"/static/generated/{output_filename}")
                print(f"âœ… Task {task_id} completed successfully!")
                logger.info(f"âœ… Task {task_id} completed successfully")
                
            except Exception as e:
                print(f"âŒ Error processing task {task_id}: {e}")
                logger.error(f"âŒ Error processing task {task_id}: {e}")
                import traceback
                traceback.print_exc()
                future.set_exception(e)
            finally:
                self.queue.task_done()

    def _run_inference(self, text: str, voice_path: str, output_path: str):
        """åŒæ­¥æ¨ç†æ–¹æ³•ï¼ˆçº¿ç¨‹æ± å†…é˜²å¾¡æ€§æ£€æŸ¥ï¼‰"""
        if self.model is None:
            logger.warning("Model not initialized in executor thread, re-initializing...")
            try:
                from voxcpm import VoxCPM
                self.model = VoxCPM.from_pretrained(
                    hf_model_id="openbmb/VoxCPM1.5",
                    load_denoiser=True,
                    optimize=False  # ç¦ç”¨ä¼˜åŒ–ä»¥é¿å…çº¿ç¨‹å®‰å…¨é—®é¢˜
                )
                logger.info(f"Model re-initialized inside executor thread. device={self.model.tts_model.device}")
            except Exception as reinit_err:
                logger.exception("Failed to reinitialize model inside executor")
                raise RuntimeError("VoxCPM Model not initialized") from reinit_err
        if self.model is None:
            raise RuntimeError("VoxCPM Model not initialized")
        
        try:
            import soundfile as sf
            
            # å¤„ç†voice_pathï¼ˆå¯èƒ½ä¸ºç©ºå­—ç¬¦ä¸²æˆ–Noneï¼‰
            prompt_wav_path = None
            prompt_text = None
            
            if voice_path and os.path.exists(voice_path):
                prompt_wav_path = voice_path
                # è¯»å–voiceçš„transcriptï¼ˆå¦‚æœæœ‰ï¼‰
                txt_path = os.path.splitext(voice_path)[0] + ".txt"
            if os.path.exists(txt_path):
                with open(txt_path, 'r', encoding='utf-8') as f:
                    prompt_text = f.read().strip()
            
            logger.info(f"Generating audio for: {text[:50]}...")
            logger.info(f"Voice reference: {prompt_wav_path or 'None'}")
            logger.info(f"Prompt text: {prompt_text[:50] if prompt_text else 'None'}")
            print(f"ğŸ¤ [Inference] Starting VoxCPM generation...")
            print(f"   Text length: {len(text)}")
            print(f"   Model device: {self.model.tts_model.device}")
            
            # è°ƒç”¨VoxCPMç”Ÿæˆ
            print(f"   Calling model.generate()...")
            wav = self.model.generate(
                text=text,
                prompt_wav_path=prompt_wav_path,  # å‚è€ƒéŸ³è‰²ï¼ˆå¯èƒ½ä¸ºNoneï¼‰
                prompt_text=prompt_text,          # å‚è€ƒæ–‡æœ¬ï¼ˆå¯èƒ½ä¸ºNoneï¼‰
                cfg_value=2.0,                   # å¼•å¯¼å¼ºåº¦
                inference_timesteps=10,           # æ¨ç†æ­¥æ•°ï¼ˆè¶Šé«˜è´¨é‡è¶Šå¥½ä½†è¶Šæ…¢ï¼‰
                normalize=False,                  # ä¸ä½¿ç”¨å¤–éƒ¨æ–‡æœ¬æ ‡å‡†åŒ–
                denoise=False,                    # ä¸ä½¿ç”¨å»å™ªï¼ˆä¿æŒåŸå§‹é‡‡æ ·ç‡ï¼‰
                retry_badcase=True,               # è‡ªåŠ¨é‡è¯•å¤±è´¥case
                retry_badcase_max_times=3,
                retry_badcase_ratio_threshold=6.0
            )
            print(f"âœ… [Inference] Model.generate() completed, output shape: {wav.shape}")
            
            # ä¿å­˜éŸ³é¢‘
            sf.write(output_path, wav, self.model.tts_model.sample_rate)
            logger.info(f"âœ… Audio saved to: {output_path}")
            
            return output_path
            
        except Exception as e:
            error_msg = str(e) if e else "Unknown error"
            logger.error(f"VoxCPM inference failed: {error_msg}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            print(f"âŒ VoxCPM inference error: {error_msg}")
            traceback.print_exc()
            raise e

    async def submit_task(self, text: str, voice_path: str):
        """æäº¤TTSä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        task_id = str(uuid.uuid4())
        future = asyncio.get_running_loop().create_future()
        
        print(f"ğŸ“¤ Submitting task {task_id} to queue")
        print(f"   Text: {text[:50]}")
        print(f"   Voice: {voice_path}")
        print(f"   Queue size before: {self.queue.qsize()}")
        
        await self.queue.put((task_id, text, voice_path, future))
        
        print(f"   Queue size after: {self.queue.qsize()}")
        print(f"âœ… Task submitted to queue")
        
        return task_id, future

# å…¨å±€å®ä¾‹
voxcpm_engine = VoxCPMEngine()

